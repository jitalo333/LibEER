{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e2349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "path = r\"C:\\Users\\Alonso\\Desktop\\Magister\\final_project\\repository\\LibEER\\LibEER\"\n",
    "\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd0c13",
   "metadata": {},
   "source": [
    "# Test data load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c31f72",
   "metadata": {},
   "source": [
    "## a) Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc506ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 (105, 32, 3500)\n",
      "1 2 (105, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NÃºmeros aleatorios entre 0 y 1\n",
    "d1 = np.random.rand(105, 32, 3500)\n",
    "d2 = np.random.rand(93, 32, 3500)\n",
    "\n",
    "# Unificamos los dos conjuntos en una lista\n",
    "unified_data = [[d1, d2]]\n",
    "\n",
    "#labels\n",
    "l1 = np.random.randint(0, 2, (105, 8))\n",
    "l2 = np.random.randint(0, 2, (93, 8))\n",
    "\n",
    "label = [[l1, l2]]\n",
    "\n",
    "subject = 0\n",
    "print(len(unified_data), len(unified_data[0]), np.array(unified_data[0][subject]).shape)\n",
    "print(len(label), len(label[0]), np.array(label[0][subject]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ffba91",
   "metadata": {},
   "source": [
    "## b) Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6881be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from  scipy.signal.windows import hann\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.fftpack import fft,ifft\n",
    "\n",
    "def feature_extraction(data, sample_rate, extract_bands, time_window, overlap, feature_type):\n",
    "    \"\"\"\n",
    "    input: information processed after bandpass filter\n",
    "    output:\n",
    "    input shape -> data:  (session, subject, trail, channel, band, filter_data)\n",
    "    output shape -> data:  (session, subject, trail, sample, channel, band, band_feature)\n",
    "    \"\"\"\n",
    "    isLds = False\n",
    "    if feature_type.endswith(\"_lds\"):\n",
    "        isLds = True\n",
    "        feature_type = feature_type[:-4]\n",
    "    fe = {\n",
    "        #'psd': psd_extraction,\n",
    "        'de': de_extraction,\n",
    "        'de_fourier': de_extraction_fourier,\n",
    "        #'de_reduced': de_reduced_extraction\n",
    "    }[feature_type]\n",
    "    feature_data = []\n",
    "    for ses_i, ses_data in enumerate(data):\n",
    "        ses_fe = []\n",
    "        for sub_i, sub_data in enumerate(ses_data):\n",
    "            sub_fe = []\n",
    "            for trail_i, trail_data in enumerate(sub_data):\n",
    "                sub_fe_data = fe(trail_data, sample_rate, extract_bands, time_window, overlap)\n",
    "                if isLds:\n",
    "                    sub_fe_data = lds(sub_fe_data)\n",
    "                sub_fe.append(sub_fe_data)\n",
    "            ses_fe.append(sub_fe)\n",
    "        feature_data.append(ses_fe)\n",
    "    return feature_data\n",
    "\n",
    "def de_extraction(data, sample_rate, extract_bands, time_window, overlap):\n",
    "    \"\"\"\n",
    "    DE feature extraction\n",
    "    :param data: original eeg data, input shape: (channel, filter_data)\n",
    "    :param sample_rate: sample rate of eeg signal\n",
    "    :param extract_bands: the frequency bands that needs to be extracted\n",
    "    :param time_window: time window of one extract part\n",
    "    :param overlap: overlap\n",
    "    :return: de feature need to be computed\n",
    "    \"\"\"\n",
    "    if extract_bands is None:\n",
    "        extract_bands = [[0.5, 4], [4, 8], [8, 14], [14, 30], [30, 50]]\n",
    "    nyq = 0.5 * sample_rate\n",
    "    noverlap = int(overlap * sample_rate)\n",
    "    window_size = int(time_window * sample_rate)\n",
    "    if noverlap != 0:\n",
    "        sample_num = (data.shape[1] - window_size) // (window_size - noverlap)\n",
    "    else:\n",
    "        sample_num = (data.shape[1]) // window_size\n",
    "    de_data = np.zeros((sample_num, data.shape[0], len(extract_bands)))\n",
    "    for b_idx, band in enumerate(extract_bands):\n",
    "        b, a = signal.butter(3, [band[0]/nyq, band[1]/nyq], 'bandpass')\n",
    "        band_data = signal.filtfilt(b, a, data)\n",
    "        t = 0\n",
    "        for i in range(sample_num):\n",
    "            # Old\n",
    "            de_data[i,:,b_idx] = 1 / 2 * np.log2(2 * np.pi * np.e * np.var(band_data[:,t:t+window_size], axis=1, ddof=1))\n",
    "            t += window_size-noverlap\n",
    "    return de_data\n",
    "\n",
    "def lds(data):\n",
    "    \"\"\"\n",
    "    Process data using a linear dynamic system approach.\n",
    "\n",
    "    :param data: Input data array with shape (time, channel, feature)\n",
    "    :return: Transformed data with shape (time, channel, feature)\n",
    "    \"\"\"\n",
    "    [num_t, num_channel, num_feature] = data.shape\n",
    "    # Flatten the channel and feature dimensions\n",
    "    data = data.reshape((data.shape[0], -1))\n",
    "\n",
    "    # Initial parameters\n",
    "    prior_correlation = 0.01\n",
    "    transition_matrix = 1\n",
    "    noise_correlation = 0.0001\n",
    "    observation_matrix = 1\n",
    "    observation_correlation = 1\n",
    "\n",
    "    # Calculate the mean for initialization\n",
    "    mean = np.mean(data, axis=0)\n",
    "    data = data.T  # Transpose for easier manipulation of time dimension\n",
    "\n",
    "    num_features, num_samples = data.shape\n",
    "    P = np.zeros(data.shape)\n",
    "    U = np.zeros(data.shape)\n",
    "    K = np.zeros(data.shape)\n",
    "    V = np.zeros(data.shape)\n",
    "\n",
    "    # Initial Kalman filter setup\n",
    "    K[:, 0] = prior_correlation * observation_matrix / (\n",
    "                observation_matrix * prior_correlation * observation_matrix + observation_correlation) * np.ones(\n",
    "        (num_features,))\n",
    "    U[:, 0] = mean + K[:, 0] * (data[:, 0] - observation_matrix * prior_correlation)\n",
    "    V[:, 0] = (np.ones((num_features,)) - K[:, 0] * observation_matrix) * prior_correlation\n",
    "\n",
    "    # Apply the Kalman filter over time\n",
    "    for i in range(1, num_samples):\n",
    "        P[:, i - 1] = transition_matrix * V[:, i - 1] * transition_matrix + noise_correlation\n",
    "        K[:, i] = P[:, i - 1] * observation_matrix / (\n",
    "                    observation_matrix * P[:, i - 1] * observation_matrix + observation_correlation)\n",
    "        U[:, i] = transition_matrix * U[:, i - 1] + K[:, i] * (\n",
    "                    data[:, i] - observation_matrix * transition_matrix * U[:, i - 1])\n",
    "        V[:, i] = (1 - K[:, i] * observation_matrix) * P[:, i - 1]\n",
    "\n",
    "    # Return the processed data, reshaping it to match the original input shape\n",
    "    return U.T.reshape((num_t, num_channel, num_feature))\n",
    "\n",
    "def segment_data_fourier(data, time_window, sample_rate, overlap):\n",
    "\n",
    "    window_len = int(time_window * sample_rate)\n",
    "\n",
    "    # Step 1: get the total number of samples\n",
    "    total_samples = data.shape[1]\n",
    "\n",
    "    # Step 2: calculate how many extra points don't fit into 200-sample blocks\n",
    "    extra = total_samples % window_len\n",
    "\n",
    "    # Step 3: trim the first `extra` samples\n",
    "    data_trimmed = data[:, extra:]  # discard from the beginning\n",
    "\n",
    "    # Step 4: reshape into blocks of shape (62, 200, num_blocks)\n",
    "    num_blocks = data_trimmed.shape[1] // window_len\n",
    "    segmented_data = data_trimmed.reshape(data.shape[0], num_blocks, window_len)\n",
    "\n",
    "    # (Optional) Reorder to (num_blocks, 62, 200) for convenience\n",
    "    segmented_data = np.transpose(segmented_data, (1, 0, 2))\n",
    "\n",
    "    return segmented_data\n",
    "\n",
    "def de_extraction_fourier(data_trial, sample_rate, extract_bands,  time_window, overlap):\n",
    "    '''\n",
    "    compute DE\n",
    "    --------\n",
    "    input:  data [n*m]          n electrodes, m time points\n",
    "            stft_para.stftn     frequency domain sampling rate\n",
    "            stft_para.fStart    start frequency of each frequency band\n",
    "            stft_para.fEnd      end frequency of each frequency band\n",
    "            stft_para.window    window length of each sample point(seconds)\n",
    "            stft_para.fs        original frequency\n",
    "    output: DE [n*l*k]        n electrodes, l windows, k frequency bands\n",
    "    '''\n",
    "    #initialize the parameters\n",
    "    fStart, fEnd = map(list, zip(*extract_bands))\n",
    "    # STFTN is the same \n",
    "    STFTN = sample_rate\n",
    "\n",
    "\n",
    "    #Convert frecuency from Hz to positions of a vector\n",
    "    fStartNum =(np.array(fStart) / sample_rate * STFTN).astype(int)\n",
    "    fEndNum = (np.array(fEnd)/sample_rate*STFTN).astype(int)\n",
    "\n",
    "    #Hanning window\n",
    "    Hlength=time_window*sample_rate\n",
    "    Hwindow=hann(Hlength)\n",
    "    #Hwindow= np.array([0.5 - 0.5 * np.cos(2 * np.pi * n / (Hlength+1)) for n in range(1,Hlength+1)])\n",
    "    de_trial = []\n",
    "    #Segment data and compute DE for each segment\n",
    "    data_trial = segment_data_fourier(np.array(data_trial), time_window, sample_rate, overlap)\n",
    "    for data in data_trial:\n",
    "        #Compute differential entropy\n",
    "        n=data.shape[0]\n",
    "        #Compute fft\n",
    "        Hdata = data*Hwindow\n",
    "        FFTdata=fft(Hdata,STFTN)\n",
    "        magFFTdata=abs(FFTdata[:, 0:int(STFTN/2)])\n",
    "        #Compute energy and de per frecuancy band\n",
    "        de = np.zeros([n,len(fStart)])\n",
    "        for i, (start, end) in enumerate(zip(fStartNum, fEndNum)):\n",
    "            band = magFFTdata[:, start:end]  # (n_channels, ancho de banda)\n",
    "            E = np.sum(band**2, axis=1) / (end - start + 1)  # (n_channels,)\n",
    "            de[:, i] = np.log2(100 * E)\n",
    "        de_trial.append(de)\n",
    "\n",
    "    return np.array(de_trial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3af9d",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c784a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "14\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "from data_utils.preprocess import baseline_removal, bandpass_filter, segment_data\n",
    "\n",
    "data = unified_data\n",
    "\n",
    "# a 1-second non-overlapping preprocess window to extract de_lds features on specified extract bands\n",
    "data = feature_extraction(data, 250, extract_bands=[[0.5,4],[4,8],[8,14],[14,30],[30,50]] , time_window=1, overlap=0, feature_type=\"de_lds\")\n",
    "# sliding window with a size of 1 and  a step size of 1 to segment the samples.\n",
    "data, feature_dim = segment_data(data, sample_length=1, stride=1)\n",
    "# data format: (session, subject, trail, sample(min*chann*bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5449002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 14, 32, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data[0][0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c264b4c",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34efac68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alonso\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "14\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "from data_utils.preprocess import baseline_removal, bandpass_filter, segment_data\n",
    "\n",
    "data = unified_data\n",
    "\n",
    "# a 1-second non-overlapping preprocess window to extract de_lds features on specified extract bands\n",
    "data = feature_extraction(data, 250, extract_bands=[[1, 4],[4,8],[8,14],[14,30],[30,50]] , time_window=1, overlap=0, feature_type=\"de_fourier_lds\")\n",
    "# sliding window with a size of 1 and  a step size of 1 to segment the samples.\n",
    "data, feature_dim = segment_data(data, sample_length=1, stride=1)\n",
    "# data format: (session, subject, trail, sample(min*chann*bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56dc8bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 14, 32, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data[0][0]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
